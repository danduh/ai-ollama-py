version: '3'
services:
  router:
    image: testsage
    networks:
      - my_network
    ports:
      - "8087"
    environment:
      - DEST_URL=http://ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
  ollama:
    image: readyollama
    networks:
      - my_network
    ports:
      - "11434:11434"
    healthcheck:
#      test: [ "CMD", "/bin/bash", "-c", "curl -sSf -X POST -H 'Content-Type: application/json' -d '{\"model\": \"llama3\", \"messages\": [{\"role\": \"user\", \"content\": \"why is the sky blue?\"}]}' http://ollama:80/healthcheck-endpoint" ]

      test: |
        ollama run llama3
      interval: 20s
      timeout: 15s
      retries: 3

networks:
  my_network:
